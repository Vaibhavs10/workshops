{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d55fd487-9ea6-4580-98a9-d19d3c1db83d",
      "metadata": {},
      "source": [
        "<!--<badge>--><a href=\"https://colab.research.google.com/github/huggingface/workshops/blob/main/europython-2022/03-gradio-demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><!--</badge>-->"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87c47386",
      "metadata": {},
      "source": [
        "# Creating a Transformers demo with Gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ee3a648-2519-4617-a206-19b8c5cfef3d",
      "metadata": {},
      "source": [
        "## References\n",
        "\n",
        "* https://huggingface.co/blog/gradio-spaces\n",
        "* https://huggingface.co/blog/gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f793dc42",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install transformers gradio sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87712d83",
      "metadata": {},
      "source": [
        "## Example 1: Using the Transformers pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "efab6bce-f259-4956-98b6-ad379e4fccd6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ce4a01e6-6143-4dec-a560-19498428f01e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-10 16:58:58.104883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-10 16:58:58.108973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-10 16:58:58.109835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-10 16:58:58.162488: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-07-10 16:58:58.165793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-10 16:58:58.167097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-10 16:58:58.168165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-10 16:58:58.487967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-10 16:58:58.488653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-10 16:58:58.489301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-10 16:58:58.489921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21654 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
            "2022-07-10 16:59:02.299047: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
            "All model checkpoint layers were used when initializing TFDebertaV2ForSequenceClassification.\n",
            "\n",
            "All the layers of TFDebertaV2ForSequenceClassification were initialized from the model checkpoint at Rocketknight1/europython-imdb.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2ForSequenceClassification for predictions without further training.\n",
            "/home/matt/PycharmProjects/transformers/src/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "pipe = pipeline(\"text-classification\", model=\"Rocketknight1/europython-imdb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e9751057",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'Negative', 'score': 0.9972227811813354}]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe(\"This was the most boring 94 minutes of my life.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e064676e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('\ud83d\ude3b', 0.98438)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label2emoji = {\"Negative\": \"\ud83d\udca9\", \"Positive\": \"\ud83d\ude3b\"}\n",
        "\n",
        "def predict(text):\n",
        "    preds = pipe(text)[0]\n",
        "    return label2emoji[preds[\"label\"]], round(preds[\"score\"], 5)\n",
        "\n",
        "predict(\"I loved this movie!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9c65091e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/matt/miniconda3/envs/tensorflow28/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/home/matt/miniconda3/envs/tensorflow28/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/home/matt/miniconda3/envs/tensorflow28/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
            "  warnings.warn(value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860/\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7f79f4618100>, 'http://127.0.0.1:7860/', None)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gradio_ui = gr.Interface(\n",
        "    fn=predict,\n",
        "    title=\"Review analysis\",\n",
        "    description=\"Enter some review text and check what the model predicts for its sentiment.\",\n",
        "    inputs=[\n",
        "        gr.inputs.Textbox(lines=5, label=\"Paste some text here\"),\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.outputs.Textbox(label=\"Label\"),\n",
        "        gr.outputs.Textbox(label=\"Score\"),\n",
        "    ],\n",
        "    examples=[\n",
        "        [\"I loved it, best movie ever!\"], [\"Turgid and preposterous, almost unwatchable.\"]\n",
        "    ],\n",
        ")\n",
        "\n",
        "gradio_ui.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a4afb5f-6f9b-42ab-881e-34870729d028",
      "metadata": {},
      "source": [
        "## Example 2: Using the Inference API from the Hugging Face Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5b440dde-e6e7-4dc0-afc0-79f097360797",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'Positive', 'score': 0.9859941005706787},\n",
              " {'label': 'Negative', 'score': 0.0140059320256114}]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from huggingface_hub import InferenceApi\n",
        "\n",
        "text = \"I loved it, best movie ever!\"\n",
        "inference = InferenceApi(\"Rocketknight1/europython-imdb\")\n",
        "preds = inference(inputs=text)\n",
        "preds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e02675d8-95d4-4874-9b30-aa375da20054",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'Positive', 'score': 0.9859941005706787},\n",
              " {'label': 'Negative', 'score': 0.0140059320256114}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted_preds = sorted(preds[0], key=lambda d: d['score'], reverse=True) \n",
        "sorted_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "96673a20-fc00-4540-b85d-3cd2696df1bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "def inference_predict(text):\n",
        "    inference = InferenceApi(\"Rocketknight1/europython-imdb\")\n",
        "    preds = inference(inputs=text)\n",
        "    sorted_preds = sorted(preds[0], key=lambda d: d['score'], reverse=True)[0]\n",
        "    return label2emoji[sorted_preds[\"label\"]], round(sorted_preds[\"score\"], 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c8250d8a-6bd1-4406-8a06-3e0de40eebd8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('\ud83d\ude3b', 0.98599)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inference_predict(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d5f756f0",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/matt/miniconda3/envs/tensorflow28/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/home/matt/miniconda3/envs/tensorflow28/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/home/matt/miniconda3/envs/tensorflow28/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
            "  warnings.warn(value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching model from: https://huggingface.co/Rocketknight1/europython-imdb\n",
            "Running on local URL:  http://127.0.0.1:7861/\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7f79f46c7d30>, 'http://127.0.0.1:7861/', None)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gradio_ui = gr.Interface.load(\n",
        "    name=\"Rocketknight1/europython-imdb\",\n",
        "    src=\"huggingface\",\n",
        "    fn=inference_predict,\n",
        "    title=\"Review analysis\",\n",
        "    description=\"Enter some text and check if model detects it's star rating.\",\n",
        "    inputs=[\n",
        "        gr.inputs.Textbox(lines=5, label=\"Paste some text here\"),\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.outputs.Textbox(label=\"Label\"),\n",
        "        gr.outputs.Textbox(label=\"Score\"),\n",
        "    ],\n",
        "    examples=[\n",
        "        [\"I loved it, best movie ever!\"], [\"Turgid and preposterous, almost unwatchable.\"]\n",
        "    ],\n",
        ")\n",
        "\n",
        "gradio_ui.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b8188dd",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "9f835d35ef2d7d572ed1f1be271ae903cca02f9a46b282db81c294a2d4ce247b"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}